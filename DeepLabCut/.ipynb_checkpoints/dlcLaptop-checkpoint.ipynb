{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepLabCut\n",
    "\n",
    "This notebook covers the installation and use of DeepLabCut on a computer that is not equipped with a GPU.\n",
    "\n",
    "You can find more information in the [DeepLabCut repository](https://github.com/AlexEMG/DeepLabCut).\n",
    "\n",
    "We will train a deep neural network to track the position of human fingers. DeepLabCut is very flexible and you can train it to track almost any object. \n",
    "\n",
    "The network will be trained using images from one video located in the course repository: `dataNeuroCourse/DeepLabCut/video/digits.avi` \n",
    "\n",
    "We will use GPUs provided by Google to train and evaluate our network.\n",
    "\n",
    "In this first notebook, we will do the following steps:\n",
    "\n",
    "1. Install Anaconda and create a DeepLabCut Anaconda environment\n",
    "2. Create a DeepLabCut project\n",
    "3. Label some frames from our video\n",
    "4. Move our project to a google drive\n",
    "\n",
    "\n",
    "## Install Anaconda\n",
    "\n",
    "The first step is to install python and all the python packages needed. The easiest way is to download and install Anaconda.\n",
    "\n",
    "https://www.anaconda.com/\n",
    "\n",
    "This will make sure you have most commonly used python packages installed on your machine.\n",
    "\n",
    "## Get DeepLabCut from GitHub\n",
    "\n",
    "https://github.com/AlexEMG/DeepLabCut\n",
    "\n",
    "Run the following command to clone the repository to you computer. In a terminal, run the following command.\n",
    "\n",
    "```git clone https://github.com/AlexEMG/DeepLabCut.git```\n",
    "\n",
    "There are several tutorials in the DeepLabCut repository. They can be very useful.\n",
    "\n",
    "\n",
    "## Install the DeepLabCut Anaconda environment\n",
    "\n",
    "The installation process depends on whether you want to use a GPU on your computer to train the network or not. Here I assume that we want to label some frames on our laptop and then train the network on Colab GPU.\n",
    "\n",
    "The latest instructions to install dlc can be found here.\n",
    "\n",
    "https://github.com/AlexEMG/DeepLabCut/blob/master/docs/installation.md\n",
    "\n",
    "\n",
    "All we need to do here is to create a new anaconda environment. The definition of the environment we need can be found in the DeepLabCut repository. The definition depends on your operating system. In my case, I used the version for Ubuntu. The ones for Windows and Mac are found in the same directory. \n",
    "\n",
    "```\n",
    "cd DeepLabCut/conda-environments\n",
    "conda env create -f DLC-CPU.yaml\n",
    "```\n",
    "\n",
    "Once you have installed the DLC-CPU environment, you will need to activate it and restart your jupyter notebook in this environment.\n",
    "\n",
    "```\n",
    "conda activate DLC-CPU\n",
    "jupyter notebook\n",
    "```\n",
    "\n",
    "You should have all you need to run deeplabcut.\n",
    "\n",
    "\n",
    "## Make sure your dlc environment is activated\n",
    "\n",
    "Make sure your DeepLabCut anaconda environment is activated in the terminal you used to run your jupyter notebook.\n",
    "Otherwise, DeepLabCut will not be available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with DeepLabCut\n",
    "\n",
    "Now we can get going with actually working with deeplabcut.\n",
    "\n",
    "The first thing to do is to load the deeplabcut package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import deeplabcut "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Have a look at the video\n",
    "\n",
    "We will track a hand in a video that you can find in the course repository.\n",
    "\n",
    "`dataNeuroCourse/DeepLabCut/video/digits.avi`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a new project\n",
    "\n",
    "It is always good idea to keep the projects seperate if you want to use different networks to analze your data. You should use one project if you are tracking similar subjects/items even if in different environments. This function creates a new project with sub-directories and a basic configuration file in the user defined directory otherwise the project is created in the current working directory.\n",
    "\n",
    "You can always add new videos (for lableing more data) to the project at any stage of the project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project \"/home/kevin/repo/dataNeuroCourse/DeepLabCut/digit_tracking_live-Allen-2020-12-21\" already exists!\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "task='digit_tracking_live' # Enter the name of your experiment Task\n",
    "experimenter='Allen' # Enter the name of the experimenter\n",
    "video=['/home/kevin/repo/dataNeuroCourse/DeepLabCut/video/digits.avi'] # Enter the paths of your videos OR FOLDER you want to grab frames from.\n",
    "\n",
    "path_config_file=deeplabcut.create_new_project(task,experimenter,video,copy_videos=True) \n",
    "# NOTE: The function returns the path, where your project is. \n",
    "# You could also enter this manually \n",
    "# (e.g. if the project is already created and you want to pick up, where you stopped...)\n",
    "#path_config_file = '/home/Mackenzie/Reaching/config.yaml' \n",
    "# Enter the path of the config file that was just created from the above step (check the folder)\n",
    "\n",
    "print(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edit the config.yaml file that was created! \n",
    "\n",
    "Add your body part labels, edit the number of frames to extract per video, etc. \n",
    "\n",
    "You can do this with any text editor.\n",
    "\n",
    "I will use my favorite text editor emacs. You will need to adjust the directory name.\n",
    "\n",
    "```\n",
    "emacs /home/kevin/repo/dataNeuroCourse/DeepLabCut/digit_tracking_live-Allen-2020-12-21/config.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract frames from our video\n",
    "\n",
    "A key point for a successful feature detector is to select diverse frames, which are typical for the behavior you study that should be labeled.\n",
    "\n",
    "This function selects N frames either uniformly sampled from a particular video (or folder) ('uniform'). Note: this might not yield diverse frames, if the behavior is sparsely distributed (consider using kmeans), and/or select frames manually etc.\n",
    "\n",
    "Also make sure to get select data from different (behavioral) sessions and different animals if those vary substantially (to train an invariant feature detector).\n",
    "\n",
    "Individual images should not be too big (i.e. < 850 x 850 pixel). Although this can be taken care of later as well, it is advisable to crop the frames, to remove unnecessary parts of the frame as much as possible.\n",
    "\n",
    "Always check the output of cropping. If you are happy with the results proceed to labeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kevin/repo/dataNeuroCourse/DeepLabCut/digit_tracking_live-Allen-2020-12-21/config.yaml\n"
     ]
    }
   ],
   "source": [
    "path_config_file = \"/home/kevin/repo/dataNeuroCourse/DeepLabCut/digit_tracking_live-Allen-2020-12-21/config.yaml\"\n",
    "print(path_config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file read successfully.\n",
      "Do you want to extract (perhaps additional) frames for video: /home/kevin/repo/dataNeuroCourse/DeepLabCut/digit_tracking_live-Allen-2020-12-21/videos/digits.avi ?\n",
      "yes/noyes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "58it [00:00, 573.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 12.98  seconds.\n",
      "Extracting and downsampling... 389  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "389it [00:00, 619.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Frames were successfully extracted, for the videos of interest.\n",
      "\n",
      "You can now label the frames using the function 'label_frames' (if you extracted enough frames for all videos).\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "#there are other ways to grab frames, such as uniformly; please see the paper:\n",
    "\n",
    "#AUTOMATIC:\n",
    "deeplabcut.extract_frames(path_config_file) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label the extracted frames\n",
    "\n",
    "Only videos in the config file can be used to extract the frames. Extracted labels for each video are stored in the project directory under the subdirectory **'labeled-data'**. Each subdirectory is named after the name of the video. The toolbox has a labeling toolbox which could be used for labeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can now check the labels, using 'check_labels' before proceeding. Then, you can use the function 'create_training_dataset' to create the training dataset.\n"
     ]
    }
   ],
   "source": [
    "%gui wx\n",
    "deeplabcut.label_frames(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move your project directory to google drives and use the colab notebook to train the network\n",
    "\n",
    "We will now move our project directory to a google drive and use [colab](https://colab.research.google.com/notebooks/welcome.ipynb) to train our network.\n",
    "\n",
    "Before moving to the Google Drive, you have to edit the path of your project in the config.yaml file of the project. It needs to point to your project directory on the google drive. In my case I used:\n",
    "\n",
    "```\n",
    "project_path: /content/drive/My Drive/teaching_and_thesis/master_neuroscience_2019/deeplabcut/digit_tracking-Allen-2019-12-18\n",
    "```\n",
    "\n",
    "Once the modification made, copy the entire project directory to your google drive.\n",
    "\n",
    "The code to train our deep neural network is in the `DeepLabCut` directory of the course repository (`dlc_colab_digit.ipynb`). Copy it to your google drive and open it with colab.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
